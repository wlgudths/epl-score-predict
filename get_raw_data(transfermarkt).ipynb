{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_epl_season_data()\n",
    "\n",
    "### 특정 시즌의 프리미어 리그 데이터를 transfermarkt 에서 가져오는 함수\n",
    "\n",
    "- param season : 가져올 시즌 연도\n",
    "- return : 해당 시즌의 팀 데이터 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrape_transfermarkt()\n",
    "\n",
    "### transfermarkt에서 여러 시즌의 프리미어 리그 데이터를 스크래핑하고 CSV 파일로 저장하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RCp2zwVZSk6y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_epl_season_data 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epl_season_data(season):\n",
    "    # transfermarkt 웹사이트 URL 구성\n",
    "    url = f'https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1/plus/?saison_id={season}'\n",
    "    \n",
    "    # 웹 스크래핑 탐지를 피하기 위한 헤더 설정\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    # 웹 페이지 요청\n",
    "    r = requests.get(url, headers=headers)\n",
    "    \n",
    "    # BeautifulSoup을 사용하여 HTML 파싱\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    # 팀 정보가 있는 테이블 행 추출 (프리미어 리그는 20개 팀만 경쟁)\n",
    "    team_info = soup.find_all('tr', {'class': ['odd', 'even']})[:20]\n",
    "    \n",
    "    season_data = []\n",
    "    for info in team_info:\n",
    "        # 각 팀의 정보 추출\n",
    "        team = info.find_all('td')\n",
    "        season_data.append([\n",
    "            season + 1,  # 시즌 (다음 해로 표시)\n",
    "            team[1].text.strip().replace('\\xa0', ''), # 팀 이름\n",
    "            int(team[2].text.strip()),  # 스쿼드 크기\n",
    "            float(team[3].text.strip()),  # 평균 나이\n",
    "            team[5].text.strip()  # 평균 시장 가치\n",
    "        ])\n",
    "    # 과도한 요청을 보내지 않기 위해 1 ~ 3 초 사이의 랜덤한 시간 동안 대기\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    return season_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrape_trasfermarkt 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_transfermarkt():\n",
    "    # 스크래핑할 시즌 범위 설정\n",
    "    seasons = range(2004, 2024)\n",
    "    all_team_data = []\n",
    "    \n",
    "    # 각 시즌의 데이터를 순차적으로 가져옴\n",
    "    for season in tqdm(seasons, desc=\"get epl season data\", unit=\"season\"): # tqdm을 사용하여 진행 상황을 시각화\n",
    "        season_data = get_epl_season_data(season)\n",
    "        all_team_data.extend(season_data)\n",
    "    \n",
    "    # 수집된 데이터로 DataFrame 생성\n",
    "    columns = ['Season', 'Club', 'Squad', 'Age', 'Market Value']\n",
    "    df = pd.DataFrame(all_team_data, columns=columns)\n",
    "    \n",
    "    # 현재 작업 디렉토리 경로\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # 'raw_data' 폴더 경로\n",
    "    raw_data_dir = os.path.join(current_dir, 'raw_data')\n",
    "    # 'raw_data' 폴더가 없으면 생성\n",
    "    os.makedirs(raw_data_dir, exist_ok=True)\n",
    "    \n",
    "    # CSV 파일 이름 설정\n",
    "    output_file = 'epl_team_info_trasnfermarkt.csv'\n",
    "    \n",
    "    # 'raw_data' 폴더 안에 CSV 파일 저장 경로 설정\n",
    "    output_path = os.path.join(raw_data_dir, output_file)\n",
    "    \n",
    "    # DataFrame을 CSV 파일로 저장\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f'{output_file} 데이터가 {output_path}에 저장되었습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "get epl season data: 100%|██████████████████| 20/20 [02:44<00:00,  8.24s/season]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epl_team_info_trasnfermarkt.csv 데이터가 /Users/sonjeehyung/Desktop/Project/승부예측/raw_data/epl_team_info_trasnfermarkt.csv에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scrape_transfermarkt()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
